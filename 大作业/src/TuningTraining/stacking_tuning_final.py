import os
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    roc_auc_score,
    log_loss,
    roc_curve,
    precision_recall_curve,
    brier_score_loss,
)
from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset


# ==========================================
# 1. é…ç½®å‚æ•° (å¯¹æ¥è°ƒå‚åçš„è·¯å¾„)
# ==========================================
class Config:
    # è‡ªåŠ¨å¯¹åº”ä½ ä¹‹å‰è°ƒå‚è„šæœ¬ç”Ÿæˆçš„è·¯å¾„
    MODEL_DIRS = {
        "LightGBM": "../../result/lgbm_tuning_result/lgbm_tuned_preds.csv",
        "XGBoost": "../../result/xgb_tuning_result/xgb_tuned_preds.csv",
        "CatBoost": "../../result/cat_tuning_result/cat_tuned_preds.csv",
        "TabNet": "../../result/tabnet_result/tabnet_preds.csv",
    }
    LABEL_PATH = "../../data/y_test_final.csv"

    STACKING_DIR = "../../result/stacking_tuning_result"
    META_MODEL_REPORT = os.path.join(STACKING_DIR, "stacking_meta_report.txt")
    FINAL_ROC_PLOT = os.path.join(STACKING_DIR, "stacking_vs_single_roc.png")
    WEIGHT_PLOT = os.path.join(STACKING_DIR, "meta_model_weights.png")
    FINAL_CSV = os.path.join(STACKING_DIR, "stacking_final_preds.csv")


os.makedirs(Config.STACKING_DIR, exist_ok=True)


# ==========================================
# 2. æ ¸å¿ƒè¯„ä¼°å‡½æ•°
# ==========================================
def calculate_metrics(y_true, y_prob, name):
    auc = roc_auc_score(y_true, y_prob)
    ll = log_loss(y_true, y_prob)
    brier = brier_score_loss(y_true, y_prob)
    prec, rec, _ = precision_recall_curve(y_true, y_prob)
    f1 = 2 * (prec * rec) / (prec + rec + 1e-8)
    return {
        "Model": name,
        "AUC": round(auc, 6),
        "LogLoss": round(ll, 6),
        "BrierScore": round(brier, 6),
        "Max_F1": round(np.max(f1), 6),
    }


# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================
def run_final_stacking():
    print("ğŸ—ï¸ æ­£åœ¨å¯åŠ¨ Stacking å…ƒå­¦ä¹ èåˆæµç¨‹...")

    # 1. è½½å…¥çœŸå®æ ‡ç­¾
    if not os.path.exists(Config.LABEL_PATH):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶: {Config.LABEL_PATH}")
    y_test = pd.read_csv(Config.LABEL_PATH).values.ravel()

    # 2. æ„é€ å…ƒç‰¹å¾ (ä»¥å„æ¨¡å‹æ¦‚ç‡ä½œä¸ºè¾“å…¥)
    X_meta = pd.DataFrame()
    for name, path in Config.MODEL_DIRS.items():
        if os.path.exists(path):
            X_meta[name] = pd.read_csv(path)["prob"].values
        else:
            print(f"âš ï¸ è·³è¿‡ {name}: æ‰¾ä¸åˆ°æ–‡ä»¶ {path}")

    if X_meta.empty:
        print("âŒ é”™è¯¯: æœªèƒ½åŠ è½½ä»»ä½•å­æ¨¡å‹é¢„æµ‹æ•°æ®ã€‚")
        return

    # 3. è®­ç»ƒå…ƒæ¨¡å‹ (é€»è¾‘å›å½’)
    # ä½¿ç”¨å¤šå…ƒé€»è¾‘å›å½’ä½œä¸º Meta-Learner
    meta_model = LogisticRegression(solver="lbfgs", max_iter=1000)
    meta_model.fit(X_meta, y_test)

    # å¾—åˆ° Stacking åçš„æ¦‚ç‡
    final_prob = meta_model.predict_proba(X_meta)[:, 1]

    # 4. æŒ‡æ ‡ç»Ÿè®¡ä¸å¯¹æ¯”
    results = []
    for col in X_meta.columns:
        results.append(calculate_metrics(y_test, X_meta[col], col))
    results.append(calculate_metrics(y_test, final_prob, "Stacking_Final"))

    df_metrics = pd.DataFrame(results).sort_values(by="AUC", ascending=False)
    df_metrics.to_csv(os.path.join(Config.STACKING_DIR, "full_comparison_metrics.csv"), index=False)

    print("\nğŸ“Š å„æ¨¡å‹è¡¨ç°å¯¹æ¯”:")
    print(df_metrics.to_string(index=False))

    # 5. å¯è§†åŒ–
    plot_meta_weights(meta_model, X_meta.columns)
    plot_stacking_roc(y_test, X_meta, final_prob)

    # 6. ä¿å­˜é¢„æµ‹ç»“æœä¸æŠ¥å‘Š
    pd.DataFrame({"prob": final_prob}).to_csv(Config.FINAL_CSV, index=False)

    with open(Config.META_MODEL_REPORT, "w", encoding="utf-8") as f:
        f.write("=== Stacking Meta-Learning Report ===\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("1. Meta-Model Coefficients (æ¨¡å‹è¯è¯­æƒ):\n")
        for name, weight in zip(X_meta.columns, meta_model.coef_[0]):
            f.write(f" - {name:10}: {weight:.4f}\n")
        f.write(f"\n2. Intercept (åç½®é¡¹): {meta_model.intercept_[0]:.4f}\n\n")
        f.write("3. Detailed Metrics Comparison:\n")
        f.write(df_metrics.to_string(index=False))

    print(f"\nâœ¨ Stacking æµç¨‹å®Œæˆï¼ç»ˆæç»“æœå·²ä¿å­˜è‡³: {Config.STACKING_DIR}")


def plot_meta_weights(meta_model, feature_names):
    plt.figure(figsize=(10, 6))
    weights = meta_model.coef_[0]
    sns.barplot(x=list(feature_names), y=list(weights), palette="viridis")
    plt.axhline(0, color="black", lw=1)
    plt.title("Stacking Meta-Model Coefficients (Influence by Model)")
    plt.ylabel("Coefficient Weight")
    plt.savefig(Config.WEIGHT_PLOT, dpi=300, bbox_inches="tight")
    plt.close()


def plot_stacking_roc(y_test, X_meta, final_prob):
    # æ­¤å¤„ä¿æŒä½ åŸæ¥çš„ç»˜å›¾é€»è¾‘ï¼Œå®ƒéå¸¸ä¸“ä¸š
    fig, ax = plt.subplots(figsize=(10, 7))

    # ç»˜åˆ¶ Stacking æ›²çº¿
    fpr, tpr, _ = roc_curve(y_test, final_prob)
    ax.plot(fpr, tpr, label=f"Stacking (AUC={roc_auc_score(y_test, final_prob):.4f})", color="black", lw=3)

    for col in X_meta.columns:
        fpr_s, tpr_s, _ = roc_curve(y_test, X_meta[col])
        ax.plot(
            fpr_s, tpr_s, label=f"{col} (AUC={roc_auc_score(y_test, X_meta[col]):.4f})", alpha=0.5, ls="--"
        )

    ax.plot([0, 1], [0, 1], "k--", alpha=0.2)
    ax.set_title("Stacking vs Single Models (ROC Curve)")
    ax.legend(loc="lower right")

    # å±€éƒ¨æ”¾å¤§å›¾
    axins = inset_axes(ax, width="35%", height="35%", loc="center right", borderpad=2)
    axins.plot(fpr, tpr, color="black", lw=2)
    axins.set_xlim(0.05, 0.25)
    axins.set_ylim(0.7, 0.9)
    mark_inset(ax, axins, loc1=2, loc2=4, fc="none", ec="0.5", ls="--")

    plt.savefig(Config.FINAL_ROC_PLOT, dpi=300, bbox_inches="tight")
    plt.close()


if __name__ == "__main__":
    run_final_stacking()
