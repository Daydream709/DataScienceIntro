import os
import pandas as pd
import numpy as np
import optuna
from sklearn.metrics import roc_auc_score, log_loss
import matplotlib.pyplot as plt
import seaborn as sns


# ==========================================
# 1. é…ç½®å‚æ•°
# ==========================================
class Config:
    # è°ƒå‚åçš„å››ä¸ªæ¨¡å‹é¢„æµ‹ç»“æœè·¯å¾„
    MODEL_PREDS = {
        "CatBoost": "../../result/cat_tuning_result/cat_tuned_preds.csv",
        "LightGBM": "../../result/lgbm_tuning_result/lgbm_tuned_preds.csv",
        "XGBoost": "../../result/xgb_tuning_result/xgb_tuned_preds.csv",
        "TabNet": "../../result/tabnet_result/tabnet_preds.csv",
    }

    # æ ‡ç­¾è·¯å¾„ (å‡è®¾ç°åœ¨åªæœ‰ä¸€åˆ— Label)
    LABEL_PATH = "../../data/y_test_final.csv"

    # è¾“å‡ºç›®å½•
    OUTPUT_DIR = "../../result/blending_tuning_result"
    N_TRIALS = 100  # æƒé‡å¯»ä¼˜è¿­ä»£æ¬¡æ•°


os.makedirs(Config.OUTPUT_DIR, exist_ok=True)


# ==========================================
# 2. è½½å…¥æ•°æ®
# ==========================================
def load_data():
    # è½½å…¥çœŸå®æ ‡ç­¾ (æ— éœ€å‰”é™¤ï¼Œç›´æ¥å¹³é“º)
    y_true = pd.read_csv(Config.LABEL_PATH).values.ravel()

    # è½½å…¥å„æ¨¡å‹é¢„æµ‹æ¦‚ç‡
    pred_dfs = {}
    for name, path in Config.MODEL_PREDS.items():
        if os.path.exists(path):
            # è·å– prob åˆ—æ•°å€¼
            pred_dfs[name] = pd.read_csv(path)["prob"].values
        else:
            print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° {name} çš„é¢„æµ‹æ–‡ä»¶ï¼Œè·¯å¾„: {path}")

    return y_true, pred_dfs


# ==========================================
# 3. Optuna å¯»ä¼˜æ ¸å¿ƒé€»è¾‘
# ==========================================
def objective(trial, y_true, pred_dfs):
    weights = {}
    # ä¸ºæ¯ä¸ªæ¨¡å‹å»ºè®®ä¸€ä¸ª 0.0 åˆ° 1.0 ä¹‹é—´çš„æƒé‡
    for name in pred_dfs.keys():
        weights[name] = trial.suggest_float(name, 0.0, 1.0)

    # æƒé‡å½’ä¸€åŒ– (Softmax æ€æƒ³ï¼šç¡®ä¿æ€»å’Œä¸º 1)
    total_w = sum(weights.values())
    if total_w == 0:
        return 0

    # è®¡ç®—åŠ æƒèåˆåçš„æœ€ç»ˆæ¦‚ç‡
    blended_prob = np.zeros_like(y_true, dtype=float)
    for name, prob in pred_dfs.items():
        blended_prob += prob * (weights[name] / total_w)

    # ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å¤§åŒ– AUC
    return roc_auc_score(y_true, blended_prob)


# ==========================================
# 4. æ‰§è¡Œèåˆ
# ==========================================
def run_blending():
    print("ğŸš€ å¯åŠ¨å…¨æ¨¡å‹æœ€ä¼˜æƒé‡æœç´¢ (CatBoost + LGBM + XGB + TabNet)...")
    y_true, pred_dfs = load_data()

    if len(pred_dfs) < 2:
        print("âŒ é”™è¯¯: æœ‰æ•ˆæ¨¡å‹ä¸è¶³ 2 ä¸ªï¼Œæ— æ³•è¿›è¡Œèåˆã€‚")
        return

    # 1. è‡ªåŠ¨æœç´¢æœ€ä¼˜æƒé‡åˆ†é…
    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, y_true, pred_dfs), n_trials=Config.N_TRIALS)

    # 2. æå–å¹¶å½’ä¸€åŒ–æœ€ä½³æƒé‡
    best_raw = study.best_params
    total_best_w = sum(best_raw.values())
    best_weights = {k: round(v / total_best_w, 4) for k, v in best_raw.items()}

    print("\nğŸ† å¯»ä¼˜ç»“æŸï¼")
    print("-" * 30)
    for name, w in best_weights.items():
        print(f" æ¨¡å‹: {name:10} | æœ€ä¼˜æƒé‡: {w:.4f}")
    print("-" * 30)
    print(f"âœ¨ èåˆåæœ€ç»ˆ AUC: {study.best_value:.6f}")

    # 3. ç”Ÿæˆå¹¶ä¿å­˜æœ€ç»ˆç»“æœ
    final_prob = np.zeros_like(y_true, dtype=float)
    for name, prob in pred_dfs.items():
        final_prob += prob * best_weights[name]

    pd.DataFrame({"prob": final_prob}).to_csv(
        os.path.join(Config.OUTPUT_DIR, "final_blended_preds.csv"), index=False
    )

    # 4. æƒé‡å æ¯”å¯è§†åŒ–
    plot_weights(best_weights)

    print(f"\nâœ… ç»ˆæèåˆé¢„æµ‹å·²ä¿å­˜è‡³: {Config.OUTPUT_DIR}")


def plot_weights(weights):
    plt.figure(figsize=(10, 6))
    names = list(weights.keys())
    vals = list(weights.values())

    colors = sns.color_palette("pastel")[0 : len(names)]
    plt.pie(vals, labels=names, autopct="%1.1f%%", startangle=140, colors=colors, explode=[0.05] * len(names))
    plt.title("Optimized Model Contribution (Ensemble Weight Distribution)")
    plt.savefig(os.path.join(Config.OUTPUT_DIR, "optimized_weights_pie.png"), dpi=300)
    plt.close()


if __name__ == "__main__":
    run_blending()
