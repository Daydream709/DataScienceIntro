import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. è·¯å¾„é…ç½®
# ==========================================
class Config:
    # æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœè·¯å¾„
    MODEL_PREDS = {
        "CatBoost": "../result/cat_tuning_result/cat_tuned_preds.csv",
        "LightGBM": "../result/lgbm_tuning_result/lgbm_tuned_preds.csv",
        "XGBoost": "../result/xgb_tuning_result/xgb_tuned_preds.csv",
        "TabNet": "../result/tabnet_result/tabnet_preds.csv",
        "Blending": "../result/blending_tuning_result/final_blended_preds.csv",
        "Stacking": "../result/stacking_tuning_result/stacking_final_preds.csv"
    }
    
    TEST_DATA_PATH = "../data/X_test_final.csv"
    OUTPUT_DIR = "../result/hit_rate_analysis"

os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

def analyze_pure_accuracy():
    print("ğŸ“Š æ­£åœ¨è¿›è¡Œ Top-1 å‘½ä¸­ç‡æ·±åº¦åˆ†æ...")
    
    # è¯»å–æµ‹è¯•æ•°æ®
    df_test = pd.read_csv(Config.TEST_DATA_PATH)
    
    # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    all_models_results = []
    
    # éå†æ‰€æœ‰æ¨¡å‹
    for model_name, pred_path in Config.MODEL_PREDS.items():
        print(f"\nğŸ” æ­£åœ¨åˆ†ææ¨¡å‹: {model_name}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pred_path):
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pred_path}")
            continue
        
        # è¯»å–å½“å‰æ¨¡å‹çš„æ¦‚ç‡
        df_preds = pd.read_csv(pred_path)
        
        # æ•´åˆå…³é”®åˆ—
        analysis_df = pd.DataFrame({
            "race_id": df_test["race_id"].values,
            "actual_rank": df_test["actual_rank"].values,
            "model_prob": df_preds["prob"].values
        })

        # 3. æ ¸å¿ƒé€»è¾‘ï¼šæ‰¾å‡ºæ¨¡å‹åœ¨æ¯åœºæ¯”èµ›ä¸­é¢„æµ‹æ¦‚ç‡æœ€é«˜çš„é©¬
        # æŒ‰ race_id åˆ†ç»„ï¼Œå¹¶æå– model_prob æœ€å¤§çš„é‚£ä¸€è¡Œ
        model_favorites = analysis_df.loc[analysis_df.groupby("race_id")["model_prob"].idxmax()].copy()

        # 4. è®¡ç®—å‡†ç¡®ç‡ï¼šæ¨¡å‹é¢„æµ‹ç¬¬ä¸€çš„é©¬ç¡®å®æ˜¯ç¬¬ä¸€åçš„æ¦‚ç‡
        total_races = len(model_favorites)
        correct_predictions = model_favorites[model_favorites['actual_rank'] == 1]
        accuracy = len(correct_predictions) / total_races if total_races > 0 else 0
        
        print(f"   --- æ¨¡å‹ {model_name} å‡†ç¡®ç‡æŠ¥å‘Š (æ€»æ¯”èµ›åœºæ¬¡: {total_races}) ---")
        print(f"   âœ… æ¨¡å‹é¢„æµ‹ç¬¬ä¸€çš„é©¬æ˜¯ç¬¬ä¸€çš„å‡†ç¡®ç‡: {accuracy:.2%}")
        
        # ä¿å­˜å½“å‰æ¨¡å‹çš„ç»“æœ
        all_models_results.append({
            'model_name': model_name,
            'total_races': total_races,
            'accuracy': accuracy
        })
    
    # ==========================================
    # æ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
    # ==========================================
    if all_models_results:
        plot_model_comparison(all_models_results)

def plot_model_comparison(all_models_results):
    # å‡†å¤‡å¯¹æ¯”æ•°æ®
    model_names = [result['model_name'] for result in all_models_results]
    accuracies = [result['accuracy'] for result in all_models_results]
    
    # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
    plt.figure(figsize=(12, 6))
    
    # å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
    colors = sns.color_palette("viridis", len(model_names))
    bars = plt.bar(model_names, accuracies, color=colors)
    
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.title('æ¨¡å‹é¢„æµ‹ç¬¬ä¸€çš„é©¬æ˜¯ç¬¬ä¸€çš„å‡†ç¡®ç‡å¯¹æ¯”')
    plt.xticks(rotation=45, ha='right')
    plt.ylim(0, 1.0)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                f'{height:.2%}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(Config.OUTPUT_DIR, "models_accuracy_comparison.png")
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"\nâœ¨ åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {output_path}")
    
    # è¾“å‡ºæ±‡æ€»è¡¨æ ¼
    print("\nğŸ“‹ æ‰€æœ‰æ¨¡å‹å‡†ç¡®ç‡æ±‡æ€»:")
    print("-" * 80)
    print(f"{'æ¨¡å‹åç§°':<15} {'é¢„æµ‹ç¬¬ä¸€æ˜¯ç¬¬ä¸€çš„å‡†ç¡®ç‡':<25}")
    print("-" * 80)
    for result in all_models_results:
        print(f"{result['model_name']:<15} {result['accuracy']:.2%}")
    print("-" * 80)

if __name__ == "__main__":
    analyze_pure_accuracy()