import os
import time
import pandas as pd
import numpy as np
import optuna
from sklearn.metrics import roc_auc_score, log_loss, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================
# 1. é…ç½®å‚æ•° (æ›´æ–°ä¸º Top 3 ä¸“ç”¨è·¯å¾„)
# ==========================================
class Config:
    # è°ƒä¼˜åçš„å››ä¸ª Top 3 æ¨¡å‹é¢„æµ‹ç»“æœè·¯å¾„
    MODEL_PREDS = {
        "CatBoost": "../../result/cat_top3_tuning_result/cat_tuned_preds_top3.csv",
        "LightGBM": "../../result/lgbm_top3_tuning_result/lgbm_tuned_preds_top3.csv",
        "XGBoost": "../../result/xgb_top3_tuning_result/xgb_tuned_preds_top3.csv",
        "TabNet": "../../result/tabnet_top3_result/tabnet_preds_top3.csv",
    }

    # Top 3 æ ‡ç­¾è·¯å¾„ (æå–æœ€åä¸€åˆ—)
    LABEL_PATH = "../../data/y_test_final_top3.csv"

    # è¾“å‡ºç›®å½•
    OUTPUT_DIR = "../../result/blending_top3_tuning_result"
    N_TRIALS = 150  # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥è·å¾—æ›´ç²¾ç»†çš„æ¯”ä¾‹
    
    # æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    REPORT_TXT = os.path.join(OUTPUT_DIR, "blending_top3_report.txt")


os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

# ==========================================
# 2. è½½å…¥æ•°æ®
# ==========================================
def load_data():
    # è½½å…¥çœŸå®æ ‡ç­¾ (æå–æœ€åä¸€åˆ—)
    y_true = pd.read_csv(Config.LABEL_PATH).iloc[:, -1].values.ravel()

    # è½½å…¥å„æ¨¡å‹é¢„æµ‹æ¦‚ç‡
    pred_dfs = {}
    for name, path in Config.MODEL_PREDS.items():
        if os.path.exists(path):
            # è·å– prob åˆ—æ•°å€¼
            pred_dfs[name] = pd.read_csv(path)["prob"].values
        else:
            print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° {name} çš„é¢„æµ‹æ–‡ä»¶ï¼Œè·¯å¾„: {path}")

    return y_true, pred_dfs

# ==========================================
# 3. Optuna å¯»ä¼˜æ ¸å¿ƒé€»è¾‘
# ==========================================
def objective(trial, y_true, pred_dfs):
    weights = {}
    for name in pred_dfs.keys():
        weights[name] = trial.suggest_float(name, 0.0, 1.0)

    # å½’ä¸€åŒ–æƒé‡
    total_w = sum(weights.values())
    if total_w == 0: return 1.0 # æƒ©ç½šé¡¹

    blended_prob = np.zeros_like(y_true, dtype=float)
    for name, prob in pred_dfs.items():
        blended_prob += prob * (weights[name] / total_w)

    # åœ¨ Top 3 ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ› AUC é«˜ä¸” LogLoss ä½
    # ç»„åˆåˆ†æ•° = AUC - LogLoss (æˆ–è€…åªçœ‹ AUC)
    auc = roc_auc_score(y_true, blended_prob)
    
    return auc

# ==========================================
# 4. æ‰§è¡Œèåˆä¸å¯è§†åŒ–
# ==========================================
# ==========================================
# 5. è®¡ç®—F1åˆ†æ•°å’Œæœ€ä½³é˜ˆå€¼
# ==========================================
def calculate_f1_and_threshold(y_true, y_prob):
    # è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œé˜ˆå€¼
    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)
    # è®¡ç®—F1åˆ†æ•°
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
    # æ‰¾åˆ°æœ€å¤§F1åˆ†æ•°å’Œå¯¹åº”çš„é˜ˆå€¼
    best_f1 = np.max(f1_scores)
    best_threshold = thresholds[np.argmax(f1_scores)] if len(thresholds) > 0 else 0.5
    return best_f1, best_threshold

# ==========================================
# 4. æ‰§è¡Œèåˆä¸å¯è§†åŒ–
# ==========================================
def run_blending():
    print(f"[{time.strftime('%H:%M:%S')}] å¯åŠ¨ Top 3 æ¨¡å‹é›†æˆå¯»ä¼˜...")
    y_true, pred_dfs = load_data()

    if len(pred_dfs) < 2:
        print("âŒ é”™è¯¯: æœ‰æ•ˆæ¨¡å‹ä¸è¶³ 2 ä¸ªã€‚")
        return

    # 1. è‡ªåŠ¨æœç´¢æœ€ä¼˜æƒé‡åˆ†é…
    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, y_true, pred_dfs), n_trials=Config.N_TRIALS)

    # 2. æå–å¹¶å½’ä¸€åŒ–æœ€ä½³æƒé‡
    best_raw = study.best_params
    total_best_w = sum(best_raw.values())
    best_weights = {k: round(v / total_best_w, 4) for k, v in best_raw.items()}

    # 3. è®¡ç®—æœ€ç»ˆèåˆæŒ‡æ ‡
    final_prob = np.zeros_like(y_true, dtype=float)
    for name, prob in pred_dfs.items():
        final_prob += prob * best_weights[name]
    
    # è®¡ç®—å„æŒ‡æ ‡
    final_auc = roc_auc_score(y_true, final_prob)
    final_loss = log_loss(y_true, final_prob)
    final_f1, final_threshold = calculate_f1_and_threshold(y_true, final_prob)

    print("\nğŸ† èåˆç»“æœæŠ¥å‘Š")
    print("=" * 40)
    for name, w in best_weights.items():
        print(f" ğŸŸ¢ {name:10} è´¡çŒ®æƒé‡: {w*100:>6.2f}%")
    print("-" * 40)
    print(f" ğŸš€ èåˆåæœ€ç»ˆ AUC: {final_auc:.6f}")
    print(f" ğŸ“‰ èåˆå LogLoss: {final_loss:.6f}")
    print(f" ğŸ¯ èåˆåæœ€ä½³ F1: {final_f1:.6f}")
    print(f" ğŸ¯ æœ€ä½³åˆ†ç±»é˜ˆå€¼: {final_threshold:.4f}")
    print("=" * 40)

    # 4. ä¿å­˜ç»“æœ
    res_df = pd.DataFrame({"prob": final_prob})
    res_df.to_csv(os.path.join(Config.OUTPUT_DIR, "final_blended_top3_preds.csv"), index=False)

    # 5. ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    generate_report(y_true, pred_dfs, best_weights, final_prob, final_auc, final_loss, final_f1, final_threshold)

    # 6. æƒé‡å æ¯”é¥¼å›¾
    plot_weights(best_weights)
    
    # 7. æ¨¡å‹ç›¸å…³æ€§çƒ­åŠ›å›¾
    plot_correlation_heatmap(pred_dfs)

# ==========================================
# 6. ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
# ==========================================
def generate_report(y_true, pred_dfs, best_weights, final_prob, final_auc, final_loss, final_f1, final_threshold):
    # è®¡ç®—å„å•ä¸€æ¨¡å‹çš„æŒ‡æ ‡
    model_metrics = []
    for name, prob in pred_dfs.items():
        auc = roc_auc_score(y_true, prob)
        loss = log_loss(y_true, prob)
        f1, threshold = calculate_f1_and_threshold(y_true, prob)
        model_metrics.append({
            "Model": name,
            "AUC": auc,
            "F1_score": f1,
            "LogLoss": loss,
            "Best_Threshold": threshold
        })
    
    # æ·»åŠ èåˆæ¨¡å‹çš„æŒ‡æ ‡
    model_metrics.append({
        "Model": "Blending",
        "AUC": final_auc,
        "F1_score": final_f1,
        "LogLoss": final_loss,
        "Best_Threshold": final_threshold
    })
    
    # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ’åº
    df_metrics = pd.DataFrame(model_metrics).sort_values(by="AUC", ascending=False)
    
    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    with open(Config.REPORT_TXT, "w", encoding="utf-8") as f:
        f.write("=============================================\n")
        f.write("      Top 3 æ¨¡å‹é›†æˆ(Blending)æŠ¥å‘Š\n")
        f.write("=============================================\n")
        f.write(f"å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # æ€§èƒ½å¯¹æ¯”æ’è¡Œæ¦œ
        f.write("ğŸ“Š [æ€§èƒ½å¯¹æ¯”æ’è¡Œæ¦œ]\n")
        f.write(" æ¨¡å‹åç§°      AUC      | F1 åˆ†æ•°  | LogLoss  | Best Threshold\n")
        f.write("-" * 65 + "\n")
        for _, row in df_metrics.iterrows():
            f.write(f" {row['Model']:10}  {row['AUC']:.6f} | {row['F1_score']:.6f} | {row['LogLoss']:.6f} | {row['Best_Threshold']:.4f}\n")
        
        # æœ€ä¼˜æƒé‡åˆ†é…
        f.write("\nâš–ï¸ [æœ€ä¼˜æƒé‡åˆ†é…]\n")
        for name, w in best_weights.items():
            f.write(f" - {name:10}: {w*100:.2f}%\n")

def plot_weights(weights):
    plt.figure(figsize=(10, 6), facecolor='white')
    names = list(weights.keys())
    vals = list(weights.values())
    
    # ä½¿ç”¨æ›´æœ‰è´¨æ„Ÿçš„é¢œè‰²
    colors = sns.color_palette("viridis", len(names))
    
    plt.pie(vals, labels=names, autopct="%1.1f%%", startangle=140, 
            colors=colors, explode=[0.03] * len(names), shadow=True)
    plt.title("Top 3 Ensemble: Optimized Model Contribution", fontsize=14)
    plt.savefig(os.path.join(Config.OUTPUT_DIR, "top3_weights_pie.png"), dpi=300)
    plt.close()

# ==========================================
# 8. æ¨¡å‹ç›¸å…³æ€§çƒ­åŠ›å›¾
# ==========================================
def plot_correlation_heatmap(pred_dfs):
    # å°†æ¨¡å‹é¢„æµ‹ç»“æœè½¬æ¢ä¸ºDataFrame
    pred_df = pd.DataFrame(pred_dfs)
    
    # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
    correlation_matrix = pred_df.corr()
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    plt.figure(figsize=(10, 8), facecolor='white')
    
    # ä½¿ç”¨seabornç»˜åˆ¶çƒ­åŠ›å›¾ï¼Œæ·»åŠ æ•°å€¼æ ‡ç­¾
    sns.heatmap(
        correlation_matrix,
        annot=True,
        cmap="coolwarm",
        fmt=".4f",
        square=True,
        cbar_kws={"shrink": 0.8},
        linewidths=0.5,
        annot_kws={"size": 12}
    )
    
    plt.title("Top 3 Models: Prediction Correlation Heatmap", fontsize=16, pad=20)
    plt.xticks(rotation=45, ha="right", fontsize=11)
    plt.yticks(rotation=0, fontsize=11)
    plt.tight_layout()
    
    # ä¿å­˜çƒ­åŠ›å›¾
    plt.savefig(os.path.join(Config.OUTPUT_DIR, "top3_model_correlation_heatmap.png"), dpi=300, bbox_inches='tight')
    plt.close()

if __name__ == "__main__":
    run_blending()