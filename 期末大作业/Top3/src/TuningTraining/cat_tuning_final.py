import os
import time
import pickle
import warnings
import optuna
import numpy as np
import pandas as pd
from catboost import CatBoostClassifier, Pool
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, log_loss, roc_curve, precision_recall_curve
from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset

warnings.filterwarnings("ignore")

# ==========================================
# 1. é…ç½®å‚æ•° (æ›´æ–°ä¸º Top 3 è·¯å¾„)
# ==========================================
class Config:
    # ä½¿ç”¨ Top 3 ä¸“ç”¨æ•°æ®
    TRAIN_FEAT_PATH = "../../data/X_train_final_top3.csv"
    TRAIN_LABEL_PATH = "../../data/y_train_final_top3.csv"
    TEST_FEAT_PATH = "../../data/X_test_final_top3.csv"
    TEST_LABEL_PATH = "../../data/y_test_final_top3.csv"

    RESULT_DIR = "../../result/cat_top3_tuning_result"
    N_TRIALS = 30

    BEST_PARAMS_PKL = os.path.join(RESULT_DIR, "best_params_top3.pkl")
    MODEL_PKL = os.path.join(RESULT_DIR, "cat_tuned_model_top3.pkl")
    PREDS_CSV = os.path.join(RESULT_DIR, "cat_tuned_preds_top3.csv")
    PLOT_PNG = os.path.join(RESULT_DIR, "cat_tuned_dashboard_top3.png")
    REPORT_TXT = os.path.join(RESULT_DIR, "cat_tuning_report_top3.txt")

os.makedirs(Config.RESULT_DIR, exist_ok=True)

# ==========================================
# 2. Optuna ç›®æ ‡å‡½æ•° (é’ˆå¯¹ Top 3 ä¼˜åŒ–)
# ==========================================
def objective(trial, X_train, y_train, X_test, y_test):
    params = {
        "iterations": 2000,
        "learning_rate": trial.suggest_float("learning_rate", 0.001, 0.05, log=True),
        "depth": trial.suggest_int("depth", 5, 8), # Top 3 ä»»åŠ¡ç¨æµ…çš„æ ‘å¾€å¾€æ³›åŒ–æ›´å¥½
        "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1.0, 15.0),
        "random_strength": trial.suggest_float("random_strength", 0.8, 3.0),
        "bagging_temperature": trial.suggest_float("bagging_temperature", 0.0, 1.0),
        # æ ¸å¿ƒï¼šæ­£æ ·æœ¬æ¯”ä¾‹ 21% æ—¶ï¼Œæƒé‡å»ºè®®åœ¨ 2.5 - 4.5 ä¹‹é—´
        "scale_pos_weight": trial.suggest_float("scale_pos_weight", 2.5, 4.5),
        "loss_function": "Logloss",
        "eval_metric": "AUC",
        "task_type": "GPU",
        "devices": "0",
        "bootstrap_type": "Bayesian",
        "verbose": False,
        "allow_writing_files": False,
    }

    model = CatBoostClassifier(**params)
    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100)

    y_prob = model.predict_proba(X_test)[:, 1]
    return roc_auc_score(y_test, y_prob)

# ==========================================
# 3. èµ„äº§ç”Ÿæˆ (1x3 çœ‹æ¿ï¼šå¢åŠ ç‰¹å¾é‡è¦æ€§)
# ==========================================
def generate_assets(y_test, y_prob, model, params):
    auc = roc_auc_score(y_test, y_prob)
    loss = log_loss(y_test, y_prob)
    prec, rec, thres = precision_recall_curve(y_test, y_prob)
    f1 = 2 * (prec * rec) / (prec + rec + 1e-8)
    max_f1, best_th = np.max(f1), thres[np.argmax(f1)]

    # 1. å†™å…¥è¯¦ç»†æŠ¥å‘Š
    with open(Config.REPORT_TXT, "w", encoding="utf-8") as f:
        f.write("=== CatBoost Top 3 è‡ªåŠ¨è°ƒå‚æŠ¥å‘Š ===\n")
        f.write(f"å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("ğŸ† æœ€ä½³è¶…å‚æ•°é…ç½®:\n")
        for k, v in params.items(): f.write(f" - {k}: {v}\n")
        f.write(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:\n")
        f.write(f" - AUC     : {auc:.6f}\n")
        f.write(f" - LogLoss : {loss:.6f}\n")
        f.write(f" - Max F1  : {max_f1:.6f}\n")
        f.write(f" - Best Th : {best_th:.4f}\n")

    # 2. åˆ›å»º 1x3 çš„çœ‹æ¿
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 7))
    
    # --- å›¾ 1: ROC Curve ---
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    ax1.plot(fpr, tpr, label=f"CatBoost Top 3 (AUC={auc:.4f})", color="#e74c3c", lw=3)
    ax1.plot([0, 1], [0, 1], "k--", alpha=0.3)
    ax1.set_title("ROC Curve (Top 3 Tasks)")
    ax1.legend()
    
    # --- å›¾ 2: PR Curve ---
    ax2.plot(rec, prec, color="#c0392b", lw=3)
    ax2.set_title("Precision-Recall (Top 3 Quality)")
    ax2.set_xlabel("Recall")
    ax2.set_ylabel("Precision")
    
    # --- å›¾ 3: Feature Importance (æ–°å¢) ---
    # è·å–ç‰¹å¾é‡è¦æ€§
    feature_importance = model.get_feature_importance()
    feature_names = model.feature_names_
    
    # æ•´ç†æ•°æ®å¹¶æ’åº
    fi_df = pd.DataFrame({'feat': feature_names, 'imp': feature_importance})
    fi_df = fi_df.sort_values(by='imp', ascending=False).head(20) # åªå–å‰20ä¸ª
    
    # ç»˜åˆ¶æ¡å½¢å›¾
    colors = plt.cm.get_cmap('YlOrRd_r')(np.linspace(0.2, 0.7, 20)) # ä½¿ç”¨çº¢æ©™è‰²ç³»
    ax3.barh(fi_df['feat'], fi_df['imp'], color=colors)
    ax3.invert_yaxis() # è®©æœ€é‡è¦çš„æ’åœ¨æœ€ä¸Šé¢
    ax3.set_title("Top 20 Features (CatBoost)")
    ax3.set_xlabel("Feature Importance Score")

    plt.tight_layout()
    plt.savefig(Config.PLOT_PNG, dpi=300)
    plt.close()
    print(f"[{time.strftime('%H:%M:%S')}] ä¸‰åˆä¸€å¯è§†åŒ–çœ‹æ¿å·²ç”Ÿæˆ: {Config.PLOT_PNG}")

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
def main():
    print(f"[{time.strftime('%H:%M:%S')}] å¯åŠ¨ Top 3 CatBoost å®éªŒ...")
    
    df_train = pd.read_csv(Config.TRAIN_FEAT_PATH)
    df_test = pd.read_csv(Config.TEST_FEAT_PATH)

    # ç‰¹å¾å¯¹é½é€»è¾‘
    # è®­ç»ƒé›†æ˜¯å…¨é‡ç‰¹å¾ï¼Œæµ‹è¯•é›†éœ€å»æ‰æœ«å°¾ 3 åˆ— (raw_win_odds, actual_rank, race_id)
    X_train = df_train.copy()
    X_test_raw = df_test.iloc[:, :-3].copy() 

    feature_names = X_train.columns.tolist()
    X_test = X_test_raw.reindex(columns=feature_names, fill_value=0)

    y_train = pd.read_csv(Config.TRAIN_LABEL_PATH).iloc[:, -1].values.ravel()
    y_test = pd.read_csv(Config.TEST_LABEL_PATH).iloc[:, -1].values.ravel()

    print(f"è®­ç»ƒé›†æ­£æ ·æœ¬ç‡: {np.mean(y_train):.2%}")

    # Optuna å¯»ä¼˜
    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=Config.N_TRIALS)

    print(f"\nâœ… å¯»ä¼˜å®Œæˆ! æœ€ä½³ AUC: {study.best_value:.6f}")

    # ç»ˆæè®­ç»ƒ
    final_params = {
        "iterations": 8000, # Top 3 æ ·æœ¬å¤šï¼Œè¿­ä»£æ¬¡æ•°å¯é€‚å½“å‡å°‘
        "loss_function": "Logloss",
        "eval_metric": "AUC",
        "task_type": "GPU",
        "early_stopping_rounds": 200,
        "verbose": 100,
        **study.best_params,
    }

    final_model = CatBoostClassifier(**final_params)
    final_model.fit(X_train, y_train, eval_set=(X_test, y_test))

    # ä¿å­˜
    y_prob = final_model.predict_proba(X_test)[:, 1]
    pd.DataFrame({"prob": y_prob}).to_csv(Config.PREDS_CSV, index=False)
    generate_assets(y_test, y_prob, final_model, study.best_params)

    with open(Config.MODEL_PKL, "wb") as f: pickle.dump(final_model, f)
    print(f"\nâœ¨ Top 3 å®éªŒå½’æ¡£è‡³: {Config.RESULT_DIR}")

if __name__ == "__main__":
    main()