import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. é…ç½®å‚æ•° (æŒ‡å‘æ‰€æœ‰æ¨¡å‹çš„ç»“æœ)
# ==========================================
class Config:
    # æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœè·¯å¾„
    MODEL_PREDS = {
        "CatBoost": "../result/cat_top3_tuning_result/cat_tuned_preds_top3.csv",
        "LightGBM": "../result/lgbm_top3_tuning_result/lgbm_tuned_preds_top3.csv",
        "XGBoost": "../result/xgb_top3_tuning_result/xgb_tuned_preds_top3.csv",
        "TabNet": "../result/tabnet_top3_result/tabnet_preds_top3.csv",
        "Blending": "../result/blending_top3_tuning_result/final_blended_top3_preds.csv",
        "Stacking": "../result/stacking_top3_result/stacking_final_preds_top3.csv"
    }
    
    # æµ‹è¯•é›†åŸå§‹ç‰¹å¾å’Œæ ‡ç­¾ (åŒ…å« race_id å’Œ actual_rank)
    TEST_DATA_PATH = "../data/X_test_final_top3.csv" 
    LABEL_PATH = "../data/y_test_final_top3.csv"
    
    OUTPUT_DIR = "../result/hit_rate_analysis"

os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

# ==========================================
# 2. æ•°æ®å‡†å¤‡ä¸å¯¹é½
# ==========================================
def analyze_accuracy():
    print("ğŸ“Š æ­£åœ¨è¿›è¡Œ Top-K å‘½ä¸­ç‡æ·±åº¦åˆ†æ...")
    
    # è¯»å–æµ‹è¯•æ•°æ®å’Œæ ‡ç­¾
    df_test = pd.read_csv(Config.TEST_DATA_PATH)
    df_label = pd.read_csv(Config.LABEL_PATH)
    
    # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    all_models_results = []
    
    # éå†æ‰€æœ‰æ¨¡å‹
    for model_name, pred_path in Config.MODEL_PREDS.items():
        print(f"\nğŸ” æ­£åœ¨åˆ†ææ¨¡å‹: {model_name}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pred_path):
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pred_path}")
            continue
        
        # è¯»å–å½“å‰æ¨¡å‹çš„æ¦‚ç‡
        df_prob = pd.read_csv(pred_path)
        
        # åˆå¹¶æˆä¸€ä¸ªåˆ†æå¤§è¡¨
        analysis_df = pd.DataFrame({
            'race_id': df_test['race_id'],
            'actual_rank': df_test['actual_rank'],
            'pred_prob': df_prob['prob'],
            'is_top3': df_label.iloc[:, -1] # çœŸå®çš„å‰ä¸‰æ ‡ç­¾
        })
        
        # ==========================================
        # æŒ‰åœºæ¬¡è®¡ç®— Top-N è¡¨ç°
        # ==========================================
        results = []
        
        # æŒ‰åœºæ¬¡åˆ†ç»„
        grouped = analysis_df.groupby('race_id')
        
        for race_id, group in grouped:
            # å¯¹è¯¥åœºæ¯”èµ›çš„é©¬åŒ¹æŒ‰é¢„æµ‹æ¦‚ç‡é™åºæ’åˆ—
            group = group.sort_values(by='pred_prob', ascending=False).reset_index(drop=True)
            
            # 1. æ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„ç¬¬ä¸€åæ˜¯å¦çœŸçš„è¿›äº†å‰ä¸‰/æ‹¿äº†ç¬¬ä¸€
            top1_actual_rank = group.loc[0, 'actual_rank']
            hit_win = 1 if top1_actual_rank == 1 else 0
            hit_place = 1 if top1_actual_rank <= 3 else 0
            
            # 2. æ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„å‰ä¸‰å (Top 3) ä¸­æœ‰å¤šå°‘çœŸçš„è·‘è¿›å‰ä¸‰
            top3_preds = group.head(3)
            hits_in_top3 = top3_preds[top3_preds['actual_rank'] <= 3].shape[0]
            
            results.append({
                'race_id': race_id,
                'top1_win_hit': hit_win,
                'top1_place_hit': hit_place,
                'top3_hits_count': hits_in_top3  # å–å€¼èŒƒå›´ 0, 1, 2, 3
            })
            
        res_df = pd.DataFrame(results)
        
        # ==========================================
        # ç»Ÿè®¡æ±‡æ€»
        # ==========================================
        total_races = len(res_df)
        avg_top1_place = res_df['top1_place_hit'].mean()
        
        # è®¡ç®— Top-3 çš„åˆ†å¸ƒæƒ…å†µ
        hit_counts = res_df['top3_hits_count'].value_counts(normalize=True).sort_index()
        
        # è®¡ç®—æ¨¡å‹è®¤ä¸ºæ˜¯å‰ä¸‰çš„é©¬ä¸­æœ‰å¤šå°‘ç¡®å®æ˜¯å‰ä¸‰
        # å³ï¼šæ¯åœºæ¯”èµ›é¢„æµ‹çš„å‰ä¸‰åŒ¹é©¬ä¸­ï¼ŒçœŸå®å‰ä¸‰çš„æ•°é‡ï¼Œç„¶åå–å¹³å‡å€¼
        top3_accuracy = res_df['top3_hits_count'].mean() / 3
        
        print(f"   --- æ¨¡å‹ {model_name} å‡†ç¡®ç‡æŠ¥å‘Š (æ€»æ¯”èµ›åœºæ¬¡: {total_races}) ---")
        print(f"   âœ… æ¨¡å‹é¦–é€‰é©¬è¿›å‰ä¸‰ç‡ (Place): {avg_top1_place:.2%}")
        print(f"   âœ… æ¨¡å‹é¢„æµ‹çš„å‰ä¸‰åä¸­ï¼ŒçœŸå®å‰ä¸‰çš„å‡†ç¡®ç‡: {top3_accuracy:.2%}")
        print(f"   âœ… æ¨¡å‹é¢„æµ‹çš„å‰ä¸‰åä¸­:")
        for count, ratio in hit_counts.items():
            print(f"      - å‘½ä¸­ {count} åŒ¹çš„åœºæ¬¡å æ¯”: {ratio:.2%}")
        
        # ä¿å­˜å½“å‰æ¨¡å‹çš„ç»“æœ
        all_models_results.append({
            'model_name': model_name,
            'total_races': total_races,
            'top1_place_accuracy': avg_top1_place,
            'top3_accuracy': top3_accuracy,
            'hit_counts': hit_counts
        })
    
    # ==========================================
    # æ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
    # ==========================================
    if all_models_results:
        plot_model_comparison(all_models_results)

def plot_model_comparison(all_models_results):
    # å‡†å¤‡å¯¹æ¯”æ•°æ®
    model_names = [result['model_name'] for result in all_models_results]
    top1_place_acc = [result['top1_place_accuracy'] for result in all_models_results]
    top3_acc = [result['top3_accuracy'] for result in all_models_results]
    
    # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
    plt.figure(figsize=(16, 8))
    
    # 1. ä¸¤ç§å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
    plt.subplot(1, 2, 1)
    x = np.arange(len(model_names))
    width = 0.35
    
    bars1 = plt.bar(x - width/2, top1_place_acc, width, label='æ¨¡å‹é¦–é€‰é©¬è¿›å‰ä¸‰ç‡', color='#1f77b4')
    bars2 = plt.bar(x + width/2, top3_acc, width, label='æ¨¡å‹é¢„æµ‹çš„å‰ä¸‰åä¸­ï¼ŒçœŸå®å‰ä¸‰çš„å‡†ç¡®ç‡', color='#2ca02c')
    
    plt.xlabel('æ¨¡å‹')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”')
    plt.xticks(x, model_names, rotation=45, ha='right')
    plt.ylim(0, 1.0)
    plt.legend()
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    def add_labels(bars):
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                    f'{height:.2%}', ha='center', va='bottom', fontsize=9)
    
    add_labels(bars1)
    add_labels(bars2)
    
    # # 2. Top-3 Accuracy å•ç‹¬å¯¹æ¯”
    # plt.subplot(1, 2, 2)
    # sorted_indices = np.argsort(top3_acc)[::-1]  # é™åºæ’åº
    # sorted_model_names = [model_names[i] for i in sorted_indices]
    # sorted_top3_acc = [top3_acc[i] for i in sorted_indices]
    
    # colors = sns.color_palette("viridis", len(sorted_model_names))
    # bars = plt.bar(sorted_model_names, sorted_top3_acc, color=colors)
    
    # plt.xlabel('æ¨¡å‹')
    # plt.ylabel('å‡†ç¡®ç‡')
    # plt.title('Top-3 å‡†ç¡®ç‡å¯¹æ¯” (æ’åº)')
    # plt.xticks(rotation=45, ha='right')
    # plt.ylim(0, 1.0)
    
    # # æ·»åŠ æ•°å€¼æ ‡ç­¾
    # for bar in bars:
    #     height = bar.get_height()
    #     plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
    #             f'{height:.2%}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(Config.OUTPUT_DIR, "models_accuracy_comparison.png")
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"\nâœ¨ åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {output_path}")
    
    # è¾“å‡ºæ±‡æ€»è¡¨æ ¼
    print("\nğŸ“‹ æ‰€æœ‰æ¨¡å‹å‡†ç¡®ç‡æ±‡æ€»:")
    print("-" * 80)
    print(f"{'æ¨¡å‹åç§°':<15} {'Top-1 Placeå‡†ç¡®ç‡':<20} {'Top-3å‡†ç¡®ç‡':<15}")
    print("-" * 80)
    for result in all_models_results:
        print(f"{result['model_name']:<15} {result['top1_place_accuracy']:.2%}{'':<10} {result['top3_accuracy']:.2%}")
    print("-" * 80)

if __name__ == "__main__":
    analyze_accuracy()