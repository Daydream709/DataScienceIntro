# 第六次作业实验文档

## 任务一：基于深度学习的学科排名预测模型

### 任务描述

在上一节课作业的基础上，利用深度学习方法，对各学科做一个排名模型，能够较好地预测出排名位置，并且利用 MSE，MAPE 等指标来进行评价模型的优劣。

### 实现过程

#### 1. 数据预处理与特征工程

首先，程序加载并预处理指定学科的数据，进行数据清洗和特征工程处理。

```python
def load_and_preprocess_data(subject_name):
    """
    加载并预处理指定学科的数据
    """
    file_path = os.path.join("download", f"{subject_name}.csv")
    if not os.path.exists(file_path):
        print(f"文件 {file_path} 不存在")
        return None

    # 尝试不同的编码格式读取数据
    try:
        # 首先尝试UTF-8编码
        df = pd.read_csv(file_path, skiprows=1, encoding="utf-8")
    except UnicodeDecodeError:
        try:
            # 如果UTF-8失败，尝试ISO-8859-1编码
            df = pd.read_csv(file_path, skiprows=1, encoding="ISO-8859-1")
        except UnicodeDecodeError:
            # 如果都失败，让pandas自动检测编码
            df = pd.read_csv(file_path, skiprows=1, encoding="utf-8-sig")

    # 清理列名
    df.columns = ["Rank", "Institution", "Country", "Documents", "Cites", "CitesPerPaper", "TopPapers"]

    # 清理数据
    df = df.dropna()

    # 将排名转换为数值型
    df["Rank"] = pd.to_numeric(df["Rank"], errors="coerce")

    # 处理数值列，确保正确转换
    df["Documents"] = pd.to_numeric(df["Documents"].astype(str).str.replace(",", ""), errors="coerce")
    df["Cites"] = pd.to_numeric(df["Cites"].astype(str).str.replace(",", ""), errors="coerce")
    df["CitesPerPaper"] = pd.to_numeric(df["CitesPerPaper"], errors="coerce")
    df["TopPapers"] = pd.to_numeric(df["TopPapers"].astype(str).str.replace(",", ""), errors="coerce")

    # 删除空值
    df = df.dropna()

    # 检查数据质量
    print(f"数据质量检查 - {subject_name}:")
    print(f"  数据量: {len(df)}")
    print(f"  排名范围: {df['Rank'].min()} - {df['Rank'].max()}")
    print(f"  文章数范围: {df['Documents'].min()} - {df['Documents'].max()}")
    print(f"  引用次数范围: {df['Cites'].min()} - {df['Cites'].max()}")

    return df
```

接着，创建扩展特征以增强模型的预测能力：

```python
def create_extended_features(df):
    """
    创建扩展特征
    """
    # 创建衍生特征
    df = df.copy()
    df["CitesPerDocument"] = df["Cites"] / (df["Documents"] + 1e-8)  # 避免除零
    df["TopPapersRatio"] = df["TopPapers"] / (df["Documents"] + 1e-8)
    df["LogDocuments"] = np.log(df["Documents"] + 1)
    df["LogCites"] = np.log(df["Cites"] + 1)
    df["LogTopPapers"] = np.log(df["TopPapers"] + 1)

    return df
```

#### 2. 模型构建

根据不同数据集大小，程序会自动选择不同复杂度的深度学习模型：

```python
def create_optimized_model(input_dim):
    """
    创建优化的深度学习模型
    """
    model = keras.Sequential(
        [
            layers.Dense(
                128, activation="relu", input_shape=(input_dim,), kernel_regularizer=regularizers.l2(0.001)
            ),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(64, activation="relu", kernel_regularizer=regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(32, activation="relu", kernel_regularizer=regularizers.l2(0.001)),
            layers.BatchNormalization(),
            layers.Dropout(0.2),
            layers.Dense(16, activation="relu", kernel_regularizer=regularizers.l2(0.001)),
            layers.Dropout(0.2),
            layers.Dense(1),
        ]
    )

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss="mse", metrics=["mae"])

    return model
```

对于小数据集，程序会使用简化模型并采用数据增强和集成学习方法：

```python
def noise_augmentation(X, y, noise_factor=0.05, n_copies=3):
    """
    添加噪声进行数据增强（适用于小数据集）
    """
    augmented_X = X.copy()
    augmented_y = y.copy()

    for _ in range(n_copies):
        # 添加高斯噪声
        noise_X = X + np.random.normal(0, noise_factor * X.std(axis=0), X.shape)
        noise_y = y + np.random.normal(0, noise_factor * y.std(), y.shape)

        augmented_X = np.vstack([augmented_X, noise_X])
        augmented_y = np.hstack([augmented_y, noise_y])

    return augmented_X, augmented_y
```

#### 3. 模型训练与评估

使用多种评估指标（MSE、MAE、MAPE、R2）来评估模型性能：

```python
# 计算测试集评估指标
test_mse = mean_squared_error(y_test, y_test_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_mape = mean_absolute_percentage_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"测试集 MSE: {test_mse:.2f}")
print(f"测试集 MAE: {test_mae:.2f}")
print(f"测试集 MAPE: {test_mape:.2f}%")
print(f"测试集 R2: {test_r2:.4f}")
```

### 实验结果

模型在各学科上的表现汇总如下：

| 学科                         | MSE                | MAE                | MAPE (%)           | R2                 |
| ---------------------------- | ------------------ | ------------------ | ------------------ | ------------------ |
| CHEMISTRY                    | 1543.025146484375  | 32.31033706665039  | 5.02301396585354   | 0.9958139061927795 |
| ENGINEERING                  | 3050.593505859375  | 41.70556640625     | 13.787981833606436 | 0.9951857328414917 |
| CLINICAL MEDICINE            | 16505.0546875      | 97.18695068359375  | 6.117185004581687  | 0.9951251149177551 |
| SOCIAL SCIENCES, GENERAL     | 3322.184326171875  | 41.599220275878906 | 10.683996144368892 | 0.993255615234375  |
| ENVIRONMENT ECOLOGY          | 2753.57861328125   | 40.93158721923828  | 5.800060347956929  | 0.9929307103157043 |
| MATERIALS SCIENCE            | 1614.2728271484375 | 33.77983856201172  | 13.044163013176115 | 0.9919337630271912 |
| IMMUNOLOGY                   | 1814.7274169921875 | 32.92778396606445  | 12.055638680197792 | 0.9843980669975281 |
| NEUROSCIENCE & BEHAVIOR      | 2350.589599609375  | 36.44740295410156  | 10.583094148487003 | 0.9824872612953186 |
| PLANT & ANIMAL SCIENCE       | 5763.40234375      | 63.55411911010742  | 10.8994508208338   | 0.9816956520080566 |
| MOLECULAR BIOLOGY & GENETICS | 2152.6884765625    | 36.09880828857422  | 12.115379474904445 | 0.9807411432266235 |
| ECONOMICS & BUSINESS         | 545.15625          | 15.218070030212402 | 19.13940100562913  | 0.9795254468917847 |
| PHARMACOLOGY & TOXICOLOGY    | 3711.505859375     | 51.82980728149414  | 31.783921977857737 | 0.9778728485107422 |
| AGRICULTURAL SCIENCES        | 3422.563232421875  | 41.65047836303711  | 16.925818914278917 | 0.9767814874649048 |
| PHYSICS                      | 2066.352783203125  | 39.38618469238281  | 17.74976063360325  | 0.9746012687683105 |
| COMPUTER SCIENCE             | 1742.27392578125   | 33.692848205566406 | 18.53145680357169  | 0.971972644329071  |
| GEOSCIENCES                  | 3273.820556640625  | 45.82994842529297  | 18.141151680814055 | 0.9710818529129028 |
| BIOLOGY & BIOCHEMISTRY       | 7006.08642578125   | 64.2135238647461   | 24.842954352309295 | 0.968795120716095  |
| PSYCHIATRY PSYCHOLOGY        | 3327.32177734375   | 41.51676940917969  | 19.05056415629705  | 0.968238115310669  |
| MICROBIOLOGY                 | 2662.49267578125   | 31.992666244506836 | 33.07573262805016  | 0.949589192867279  |
| MATHEMATICS                  | 879.318359375      | 19.840171813964844 | 34.63968176612465  | 0.9310742020606995 |
| SPACE SCIENCE                | 739.0665893554688  | 22.356597900390625 | 26.606808978188024 | 0.8443828821182251 |
| MULTIDISCIPLINARY            | 736.7789306640625  | 21.768522262573242 | 32.83751079889027  | 0.7813141345977783 |

模型在大多数学科上都表现出色，R2 值均在 0.9 以上，表明模型具有良好的预测能力。

## 任务二：基于聚类分析发现与华东师范大学相似的高校

### 任务描述

对 ESI 的数据进行聚类，发现与华师大类似的学校有哪些，并分析原因。

### 实现过程

#### 1. 数据加载与指标计算

首先加载所有学科数据，并计算各大学的综合指标：

```python
def calculate_university_indicators(all_data):
    """计算各大学的指标"""
    # 获取所有大学名称
    all_universities = set()
    for df in all_data.values():
        all_universities.update(df["Institution"].dropna().unique())

    university_indicators = {}

    for university in all_universities:
        # 初始化指标
        indicators = {
            "university_name": university,
            "total_subjects": 0,
            "top_subjects": 0,  # 排名<=100
            "high_subjects": 0,  # 排名101-500
            "medium_subjects": 0,  # 排名501-1000
            "other_subjects": 0,  # 排名>1000
            "total_documents": 0,
            "total_cites": 0,
            "avg_cites_per_paper": 0,
            "subjects_in_top_500": [],
        }

        total_cites_per_paper = 0
        count_cites_per_paper = 0

        # 遍历所有学科数据
        for subject, df in all_data.items():
            uni_data = df[df["Institution"] == university]
            if not uni_data.empty:
                indicators["total_subjects"] += 1

                rank = uni_data["Rank"].iloc[0]
                # 确保rank是数字类型
                if pd.notna(rank):
                    rank = pd.to_numeric(rank, errors="coerce")

                if pd.notna(rank):
                    if rank <= 100:
                        indicators["top_subjects"] += 1
                    elif rank <= 500:
                        indicators["high_subjects"] += 1
                    elif rank <= 1000:
                        indicators["medium_subjects"] += 1
                    else:
                        indicators["other_subjects"] += 1

                    if rank <= 500:
                        indicators["subjects_in_top_500"].append(subject)
                else:
                    # 如果rank是NaN，我们将它归类为"其他"
                    indicators["other_subjects"] += 1
                    continue  # 跳过这个学科的其他处理

                documents = uni_data["Documents"].iloc[0]
                cites = uni_data["Cites"].iloc[0]
                cites_per_paper = uni_data["CitesPerPaper"].iloc[0]

                # 确保数值列也被正确解析
                if pd.notna(documents):
                    documents = pd.to_numeric(str(documents).replace(",", ""), errors="coerce")
                if pd.notna(cites):
                    cites = pd.to_numeric(str(cites).replace(",", ""), errors="coerce")
                if pd.notna(cites_per_paper):
                    cites_per_paper = pd.to_numeric(cites_per_paper, errors="coerce")

                if pd.notna(documents):
                    indicators["total_documents"] += documents
                if pd.notna(cites):
                    indicators["total_cites"] += cites
                if pd.notna(cites_per_paper):
                    total_cites_per_paper += cites_per_paper
                    count_cites_per_paper += 1

        # 计算平均篇均引用次数
        if count_cites_per_paper > 0:
            indicators["avg_cites_per_paper"] = total_cites_per_paper / count_cites_per_paper

        university_indicators[university] = indicators

    return university_indicators
```

#### 2. 聚类分析

使用 K-Means 算法对大学进行聚类分析：

```python
def perform_clustering(df_clustering, n_clusters=5):
    """执行聚类分析"""
    # 提取数值特征用于聚类
    feature_columns = [
        "total_subjects",
        "top_subjects",
        "high_subjects",
        "medium_subjects",
        "other_subjects",
        "total_documents",
        "total_cites",
        "avg_cites_per_paper",
        "subjects_in_top_500_count",
    ]

    X = df_clustering[feature_columns]

    # 数据标准化
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # 执行K-Means聚类
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_scaled)

    # 将聚类结果添加到DataFrame
    df_clustering["cluster"] = cluster_labels

    return df_clustering, scaler, kmeans
```

#### 3. 寻找相似大学

找出与华东师范大学在同一簇的大学：

```python
def find_similar_to_ecnu(df_clustering):
    """找出与华东师范大学相似的大学"""
    # 查找华东师范大学所在的簇
    ecnu_data = df_clustering[
        (df_clustering["university_name"] == "EAST CHINA NORMAL UNIVERSITY")
        | (df_clustering["university_name"] == "华东师范大学")
    ]

    if ecnu_data.empty:
        print("未找到华东师范大学的数据")
        return

    ecnu_cluster = ecnu_data["cluster"].iloc[0]
    print(f"\n华东师范大学被分配到簇 {ecnu_cluster}")

    # 获取同一簇中的所有大学
    similar_universities = df_clustering[df_clustering["cluster"] == ecnu_cluster]

    print(f"\n与华东师范大学相似的大学 (同一簇中的大学):")
    print("=" * 50)
    for i, (idx, row) in enumerate(similar_universities.iterrows(), 1):
        print(f"{i}. {row['university_name']}")

    # 保存相似大学到单独的CSV文件
    if not os.path.exists("second_model_results"):
        os.makedirs("second_model_results")
    similar_universities.to_csv("second_model_results/ecnu_similar_universities.csv", index=False, encoding="utf-8-sig")
    print(f"\n与华东师范大学相似的大学已保存到 second_model_results/ecnu_similar_universities.csv")

    return similar_universities
```

### 实验结果

- 通过聚类分析，我们成功将大学聚类，结果保存在[clustering_results.csv](./second_model_results/clustering_results.csv)
- 聚类的可视化结果如下图：
  ![](./second_model_results/clustering_visualization.png)
- 各簇的特征分布如下图：
  ![](./second_model_results/cluster_radar_chart.png)
- 同时也成功找出了与华东师范大学相似的大学，华东师范大学被分为簇 1，相同簇的大学保存在[ecnu_similar_universities.csv](./second_model_results/ecnu_similar_universities.csv)
  这些大学与华东师范大学具有相似的特征，如学科数量、顶尖学科数量、论文总数、引用次数等指标相近。

## 总结

本次实验成功完成了两个任务：

1. 建立了基于深度学习的学科排名预测模型，能够较好地预测大学在各学科中的排名。
2. 通过对 ESI 数据进行聚类分析，找到了与华东师范大学相似的大学，并将结果保存在`second_model_results/ecnu_similar_universities.csv`文件中。

这两个任务的完成为后续的数据分析和高校评估提供了有力的工具和参考。
